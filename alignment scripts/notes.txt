For sanity
	./score.local.py ../data/GoogleNews-vectors-negative300.bin ../data/glove.6B.300d.txt.word2vec ../data/lexsub.tsv ../data/corrected.tsv ../data/gigaword4.5g.kenlm.bin
	./normalize.py scored.tsv  testing
	%s/\t/ /g *.tsvs
	cat anno tsv > feats
	cat *.feats | sort -R > maxent.feats
	then run score_ablation.ipynb

./score.sanity.py ../data/GoogleNews-vectors-negative300.bin ../data/glove.6B.300d.txt.word2vec ../data/multiple.cleaned.tsv ../data/corrected.tsv ../data/gigaword4.5g.kenlm.bin
mv scored.tsv multiple.scored.tsv

./score.sanity.py ../data/GoogleNews-vectors-negative300.bin ../data/glove.6B.300d.txt.word2vec ../data/lexsub.tsv ../data/corrected.tsv ../data/gigaword4.5g.kenlm.bin
mv scored.tsv lexsub.scored.tsv


 cut -f 1-40 lexsub.scored.tsv | perl -pe 's/\t/ /g' | grep -v "glove_src_para_sim" > lexsub.feats.tsv
 cut -f 1-40 multiple.scored.tsv | perl -pe 's/\t/ /g' | grep -v "glove_src_para_sim" > multiple.feats.tsv

 cut -f 51 multiple.scored.tsv | egrep -v "^\t" > multiple.anno.tsv
 cut -f 53 lexsub.scored.tsv | egrep -v "^\t"  > lexsub.anno.tsv

paste lexsub.anno.tsv lexsub.feats.tsv > lexsub.ready.tsv
paste multiple.anno.tsv multiple.feats.tsv > multiple.ready.tsv

cat lexsub.ready.tsv multiple.ready.tsv > sanity.feats

python score_noclass.py > sanity_output.tsv